# Query-Driven Web Scraper & Evaluator

A Streamlit-based pipeline that takes a natural-language query, performs deep semantic analysis, discovers relevant web pages via DuckDuckGo, scrapes and cleans their content (with NeuScraper + fallback), verifies relevance and content type with an LLM, semantically matches to user intent, then extracts exactly the requested information.

Additionally, a full evaluation harness (under `tests/`) computes precision/recall/F1/latency for each stage against ground-truth JSON fixtures.

---

## Features

- **Semantic Query Analysis** (`utils/semantic_analysis.py`)  
  ‚Ä¢ Breaks down user queries into search terms, expected output format, filters, and clarifications using an LLM.  
  ‚Ä¢ Provides both initial intent and deep multi-dimensional analysis.

- **Search** (`utils/search.py`)  
  ‚Ä¢ DuckDuckGo integration to retrieve top N URLs for a query.  
  ‚Ä¢ Supports optional domain-restricted searches.

- **Scraping** (`utils/scraping.py`)  
  ‚Ä¢ Primary extraction via NeuScraper API.  
  ‚Ä¢ Fallback HTML fetch + `trafilatura` cleanup.  
  ‚Ä¢ Caching and file-output of scraped text.

- **Relevance Checking** (`utils/relevance_check.py`)  
  ‚Ä¢ LLM-based semantic relevance scoring.  
  ‚Ä¢ Filters out irrelevant pages early.

- **Content-Type Verification & Semantic Match** (`utils/content_match.py`)  
  ‚Ä¢ Determines if content matches expected type (review, tutorial, news, comparison, etc.).  
  ‚Ä¢ Verifies semantic match to the user‚Äôs intent (e.g. actual product comparisons, real reviews).

- **Parsing & Field Extraction** (`utils/parsing.py`)  
  ‚Ä¢ Rule-based + LLM-enhanced parsing to extract reviewer names and review text.  
  ‚Ä¢ Generalized functions to explain parsing and generate structured responses.

- **Streamlit UI** (`app.py`)  
  ‚Ä¢ Interactive front end to enter queries and optional website constraint.  
  ‚Ä¢ Displays each processing stage, caching, conversation history, and scraped content.

- **Evaluation Harness** (`tests/`)  
  ‚Ä¢ `tests/relevance_classification.py`  
  ‚Ä¢ `tests/content_type_matching.py`  
  ‚Ä¢ `tests/semantic_matching.py`  
  ‚Ä¢ `tests/field_extraction.py`  
  ‚Ä¢ `tests/evaluator.py`  
  ‚Ä¢ Ground-truth fixtures under `tests/data/` for end-to-end metric reporting.

---

## üìÅ Repository Structure

![image](https://github.com/user-attachments/assets/b75b1b2e-77fd-42a7-92de-960de37c62c1)


---

---

## ‚öôÔ∏è Prerequisites

- **Python 3.8+**  
- **Git**  
- **Streamlit CLI**  
- **NeuScraper** running at `NEUSCRAPER_URL` (default `http://127.0.0.1:1688/predict/`)

---

## üõ† Installation

```bash
# Clone the repo
git clone git@github.com:uol-feps-soc-comp3931-project-2425/individual-project-SiddeshROhri23.git
cd individual-project-SiddeshROhri23

# Create & activate a virtual environment
python3 -m venv .venv
source .venv/bin/activate    # macOS/Linux
# .\.venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt

# Configure environment variables
echo "NEUSCRAPER_URL=http://127.0.0.1:1688/predict/" > .env
```
## Running the App
```bash
streamlit run app.py
```
## From project root:
```bash
python tests/relevance_classification.py
python tests/content_type_matching.py
python tests/semantic_matching.py
python tests/field_extraction.py
```

## Or run everything via:
```bash
python tests/evaluator.py
```

Built with ‚ù§Ô∏è by Siddesh R Ohri.
